{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsAc7WIXK3F9",
        "outputId": "3db1fc56-aa18-4539-bc01-1ada823e08e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: findspark in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pyarrow==0.14.1 (from versions: 0.9.0, 0.10.0, 0.11.0, 0.11.1, 0.12.0, 0.12.1, 0.13.0, 0.14.0, 0.15.1, 0.16.0, 0.17.0, 0.17.1, 1.0.0, 1.0.1, 2.0.0, 3.0.0, 4.0.0, 4.0.1, 5.0.0, 6.0.0, 6.0.1, 7.0.0, 8.0.0, 9.0.0, 10.0.0, 10.0.1, 11.0.0, 12.0.0, 12.0.1, 13.0.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pyarrow==0.14.1\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Collecting numpy==1.19.5\n",
            "  Using cached numpy-1.19.5.zip (7.3 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: numpy\n",
            "  Building wheel for numpy (pyproject.toml) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Installing required packages\n",
        "!pip install pyspark\n",
        "!pip install findspark\n",
        "!pip install pyarrow==0.14.1\n",
        "!pip install pandas\n",
        "!pip install numpy==1.19.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "xVWhRXweLbs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "UX_6owrMLfaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a spark context class\n",
        "sc = SparkContext()\n",
        "\n",
        "# Creating a spark session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark DataFrames basic example\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "mWL5n_nMLnzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "pnOdcX_HLsTU",
        "outputId": "e4a85aee-e803-4414-db07-de481d92b18f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7e51de693c40>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://a8d7f27bdab3:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "customSchema = StructType([\n",
        "    StructField(\"ngram\", StringType(), True),\n",
        "    StructField(\"Year\", IntegerType(), True),\n",
        "    StructField(\"Count\", IntegerType(), True),\n",
        "    StructField(\"Pages\", IntegerType(), True),\n",
        "    StructField(\"Books\", IntegerType(), True)])\n",
        "\n",
        "df = spark.read.format(\"csv\") \\\n",
        "    .option(\"header\", \"false\") \\\n",
        "    .option(\"delimiter\", \"\\t\") \\\n",
        "    .schema(customSchema) \\\n",
        "    .load(\"ngram.csv\")\n",
        "\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIPtLAB9L-jy",
        "outputId": "afb9ed26-4431-4a69-de2e-b0b66e1e8488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+-----+-----+-----+\n",
            "|   ngram|Year|Count|Pages|Books|\n",
            "+--------+----+-----+-----+-----+\n",
            "|! $17.95|1985|    1|    1|    1|\n",
            "|! $17.95|1987|    1|    1|    1|\n",
            "|! $17.95|1990|    1|    1|    1|\n",
            "|! $17.95|1991|    1|    1|    1|\n",
            "|! $17.95|1992|    5|    5|    5|\n",
            "|! $17.95|1993|    2|    2|    2|\n",
            "|! $17.95|1995|    1|    1|    1|\n",
            "|! $17.95|1996|    4|    2|    2|\n",
            "|! $17.95|1997|    6|    5|    5|\n",
            "|! $17.95|1998|    4|    3|    3|\n",
            "|! $17.95|1999|   11|   10|   10|\n",
            "|! $17.95|2000|   11|    9|    9|\n",
            "|! $17.95|2001|    5|    4|    4|\n",
            "|! $17.95|2002|    5|    5|    5|\n",
            "|! $17.95|2003|    2|    2|    2|\n",
            "|! $17.95|2004|   14|   14|   14|\n",
            "|! $17.95|2005|   13|   13|   13|\n",
            "|! $17.95|2006|    5|    5|    5|\n",
            "|! $17.95|2007|    2|    2|    2|\n",
            "|! $17.95|2008|    2|    2|    2|\n",
            "+--------+----+-----+-----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAwNXev-Nr_c",
        "outputId": "5f8c0b47-05a4-4881-c59a-163f1bd78027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ngram', 'Year', 'Count', 'Pages', 'Books']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.registerTempTable(\"ngrams\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptzSr06ONx8m",
        "outputId": "d5570778-1255-4011-b25b-d9c2e594aabe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
            "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkConf, SparkContext, SQLContext\n",
        "sqlContext = SQLContext(sc)\n",
        "print(\"hey\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmPWJEtCONHC",
        "outputId": "dfb669f2-8b5f-4fb9-ce42-90f3a31819f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hey\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1) Retourner tous les bi-grammes dont le nombre Count est supérieur à cinq.\n",
        "result_3_1_sql = spark.sql(\"SELECT * FROM ngrams WHERE Count > 5\")\n",
        "result_3_1_df = df.filter(df.Count > 5)\n",
        "result_3_1_sql.show()\n",
        "print(\"**********************\")\n",
        "result_3_1_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9wfQDXPPH7-",
        "outputId": "5c44e070-1915-4a3b-854f-f54e008ae4de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+-----+-----+-----+\n",
            "|   ngram|Year|Count|Pages|Books|\n",
            "+--------+----+-----+-----+-----+\n",
            "|! $17.95|1997|    6|    5|    5|\n",
            "|! $17.95|1999|   11|   10|   10|\n",
            "|! $17.95|2000|   11|    9|    9|\n",
            "|! $17.95|2004|   14|   14|   14|\n",
            "|! $17.95|2005|   13|   13|   13|\n",
            "|    ! 09|1899|    6|    6|    5|\n",
            "|    ! 09|1916|    7|    7|    4|\n",
            "|    ! 09|1936|    6|    6|    6|\n",
            "|    ! 09|1997|    6|    5|    5|\n",
            "|    ! 09|1999|   11|   10|   10|\n",
            "|    ! 09|2000|   11|    9|    9|\n",
            "|    ! 09|2004|   14|   14|   14|\n",
            "|    ! 09|2005|   13|   13|   13|\n",
            "+--------+----+-----+-----+-----+\n",
            "\n",
            "**********************\n",
            "+--------+----+-----+-----+-----+\n",
            "|   ngram|Year|Count|Pages|Books|\n",
            "+--------+----+-----+-----+-----+\n",
            "|! $17.95|1997|    6|    5|    5|\n",
            "|! $17.95|1999|   11|   10|   10|\n",
            "|! $17.95|2000|   11|    9|    9|\n",
            "|! $17.95|2004|   14|   14|   14|\n",
            "|! $17.95|2005|   13|   13|   13|\n",
            "|    ! 09|1899|    6|    6|    5|\n",
            "|    ! 09|1916|    7|    7|    4|\n",
            "|    ! 09|1936|    6|    6|    6|\n",
            "|    ! 09|1997|    6|    5|    5|\n",
            "|    ! 09|1999|   11|   10|   10|\n",
            "|    ! 09|2000|   11|    9|    9|\n",
            "|    ! 09|2004|   14|   14|   14|\n",
            "|    ! 09|2005|   13|   13|   13|\n",
            "+--------+----+-----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.2) Retourner le nombre total de bi-grammes dans chaque année.\n",
        "result_3_2_sql = spark.sql(\"SELECT Year, COUNT(*) as Total FROM ngrams GROUP BY Year\")\n",
        "result_3_2_df = df.groupBy(\"Year\").count()\n",
        "result_3_2_sql.show()\n",
        "result_3_2_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAyw0_LbPxVX",
        "outputId": "5f57e6de-39c1-4fb3-8eb1-85a8df54e161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|Year|Total|\n",
            "+----+-----+\n",
            "|1829|    1|\n",
            "|1990|    2|\n",
            "|1903|    1|\n",
            "|1884|    1|\n",
            "|1888|    1|\n",
            "|1924|    1|\n",
            "|2003|    2|\n",
            "|1823|    1|\n",
            "|2007|    2|\n",
            "|1869|    1|\n",
            "|1892|    1|\n",
            "|1889|    1|\n",
            "|1927|    1|\n",
            "|1866|    1|\n",
            "|1877|    1|\n",
            "|2006|    2|\n",
            "|1908|    1|\n",
            "|1925|    1|\n",
            "|1824|    1|\n",
            "|1848|    1|\n",
            "+----+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "+----+-----+\n",
            "|Year|count|\n",
            "+----+-----+\n",
            "|1829|    1|\n",
            "|1990|    2|\n",
            "|1903|    1|\n",
            "|1884|    1|\n",
            "|1888|    1|\n",
            "|1924|    1|\n",
            "|2003|    2|\n",
            "|1823|    1|\n",
            "|2007|    2|\n",
            "|1869|    1|\n",
            "|1892|    1|\n",
            "|1889|    1|\n",
            "|1927|    1|\n",
            "|1866|    1|\n",
            "|1877|    1|\n",
            "|2006|    2|\n",
            "|1908|    1|\n",
            "|1925|    1|\n",
            "|1824|    1|\n",
            "|1848|    1|\n",
            "+----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "from pyspark.sql.functions import col, dense_rank, desc, countDistinct, window\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "result_3_3_sql = spark.sql(\"SELECT * FROM (SELECT *, dense_rank() OVER (PARTITION BY Year ORDER BY Count DESC) as rnk FROM ngrams) WHERE rnk = 1\")\n",
        "\n",
        "result_3_3_df = df.withColumn(\"rnk\", dense_rank().over(Window.partitionBy(\"Year\").orderBy(desc(\"Count\")))).filter(col(\"rnk\") == 1)\n",
        "result_3_3_sql.show()\n",
        "result_3_3_df.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqXTRuk5QEKe",
        "outputId": "c6f08c04-70a0-4f37-8b19-2da2847b5641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+-----+-----+-----+---+\n",
            "|ngram|Year|Count|Pages|Books|rnk|\n",
            "+-----+----+-----+-----+-----+---+\n",
            "| ! 09|1780|    1|    1|    1|  1|\n",
            "| ! 09|1803|    1|    1|    1|  1|\n",
            "| ! 09|1806|    1|    1|    1|  1|\n",
            "| ! 09|1823|    1|    1|    1|  1|\n",
            "| ! 09|1824|    1|    1|    1|  1|\n",
            "| ! 09|1825|    1|    1|    1|  1|\n",
            "| ! 09|1829|    3|    3|    3|  1|\n",
            "| ! 09|1830|    2|    2|    2|  1|\n",
            "| ! 09|1831|    1|    1|    1|  1|\n",
            "| ! 09|1833|    1|    1|    1|  1|\n",
            "| ! 09|1834|    4|    4|    4|  1|\n",
            "| ! 09|1836|    1|    1|    1|  1|\n",
            "| ! 09|1839|    1|    1|    1|  1|\n",
            "| ! 09|1840|    1|    1|    1|  1|\n",
            "| ! 09|1841|    2|    2|    2|  1|\n",
            "| ! 09|1845|    1|    1|    1|  1|\n",
            "| ! 09|1847|    2|    2|    2|  1|\n",
            "| ! 09|1848|    1|    1|    1|  1|\n",
            "| ! 09|1856|    1|    1|    1|  1|\n",
            "| ! 09|1857|    2|    2|    2|  1|\n",
            "+-----+----+-----+-----+-----+---+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-----+----+-----+-----+-----+---+\n",
            "|ngram|Year|Count|Pages|Books|rnk|\n",
            "+-----+----+-----+-----+-----+---+\n",
            "| ! 09|1780|    1|    1|    1|  1|\n",
            "| ! 09|1803|    1|    1|    1|  1|\n",
            "| ! 09|1806|    1|    1|    1|  1|\n",
            "| ! 09|1823|    1|    1|    1|  1|\n",
            "| ! 09|1824|    1|    1|    1|  1|\n",
            "| ! 09|1825|    1|    1|    1|  1|\n",
            "| ! 09|1829|    3|    3|    3|  1|\n",
            "| ! 09|1830|    2|    2|    2|  1|\n",
            "| ! 09|1831|    1|    1|    1|  1|\n",
            "| ! 09|1833|    1|    1|    1|  1|\n",
            "| ! 09|1834|    4|    4|    4|  1|\n",
            "| ! 09|1836|    1|    1|    1|  1|\n",
            "| ! 09|1839|    1|    1|    1|  1|\n",
            "| ! 09|1840|    1|    1|    1|  1|\n",
            "| ! 09|1841|    2|    2|    2|  1|\n",
            "| ! 09|1845|    1|    1|    1|  1|\n",
            "| ! 09|1847|    2|    2|    2|  1|\n",
            "| ! 09|1848|    1|    1|    1|  1|\n",
            "| ! 09|1856|    1|    1|    1|  1|\n",
            "| ! 09|1857|    2|    2|    2|  1|\n",
            "+-----+----+-----+-----+-----+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.4) Retourner tous les bi-grammes qui sont apparus dans 20 années différentes.\n",
        "result_3_4_sql = spark.sql(\"SELECT ngram FROM (SELECT ngram, COUNT(DISTINCT Year) as num_years FROM ngrams GROUP BY ngram) WHERE num_years = 20\")\n",
        "result_3_4_df = df.groupBy(\"ngram\").agg(countDistinct(\"Year\").alias(\"num_years\")).filter(col(\"num_years\") == 20)\n",
        "result_3_4_sql.show()\n",
        "result_3_4_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7vS5TiBQ7N6",
        "outputId": "490490bc-099e-461c-d22d-fcee8e4c3190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|   ngram|\n",
            "+--------+\n",
            "|! $17.95|\n",
            "+--------+\n",
            "\n",
            "+--------+---------+\n",
            "|   ngram|num_years|\n",
            "+--------+---------+\n",
            "|! $17.95|       20|\n",
            "+--------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.5) Retourner tous les bi-grammes qui contiennent le caractère ‘!’ dans la première partie et le caractère ‘9’ dans la deuxième partie.\n",
        "from pyspark.sql.functions import col\n",
        "result_3_5_sql = spark.sql(\"SELECT * FROM ngrams WHERE ngram LIKE '%!% 9%' ESCAPE '!'\")\n",
        "result_3_5_sql.show()\n",
        "result_3_5_df = df.filter((col(\"ngram\").like(\"%!% 9%\")))\n",
        "result_3_5_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsJemLEERTYm",
        "outputId": "29c86996-e63a-48f8-a054-dcd80c53313a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+-----+-----+-----+\n",
            "|ngram|Year|Count|Pages|Books|\n",
            "+-----+----+-----+-----+-----+\n",
            "+-----+----+-----+-----+-----+\n",
            "\n",
            "+-----+----+-----+-----+-----+\n",
            "|ngram|Year|Count|Pages|Books|\n",
            "+-----+----+-----+-----+-----+\n",
            "+-----+----+-----+-----+-----+\n",
            "\n",
            "+-----+----+-----+-----+-----+\n",
            "|ngram|Year|Count|Pages|Books|\n",
            "+-----+----+-----+-----+-----+\n",
            "+-----+----+-----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_3_6_sql = spark.sql(\"SELECT ngram FROM ngrams GROUP BY ngram HAVING COUNT(DISTINCT Year) = (SELECT COUNT(DISTINCT Year) FROM ngrams)\")\n",
        "result_3_6_sql.show()\n",
        "result_3_6_df = df.groupBy(\"ngram\").agg(countDistinct(\"Year\").alias(\"num_years\")).filter(col(\"num_years\") == df.select('Year').distinct().count())\n",
        "result_3_6_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE1SAaUlSb8y",
        "outputId": "0e9074c2-115a-49c6-b840-3adbed328662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|ngram|\n",
            "+-----+\n",
            "| ! 09|\n",
            "+-----+\n",
            "\n",
            "+-----+---------+\n",
            "|ngram|num_years|\n",
            "+-----+---------+\n",
            "| ! 09|      100|\n",
            "+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.7) Retourner le nombre total de pages et de livres dans lesquels chaque bi-gramme apparaît pour chaque année disponible, trié par ordre alphabétique.\n",
        "result_3_7_sql = spark.sql(\"SELECT ngram, Year, SUM(Pages) as Total_Pages, SUM(Books) as Total_Books FROM ngrams GROUP BY ngram, Year ORDER BY ngram\")\n",
        "result_3_7_df = df.groupBy(\"ngram\", \"Year\").agg({\"Pages\": \"sum\", \"Books\": \"sum\"}).orderBy(\"ngram\")\n",
        "result_3_7_sql.show()\n",
        "result_3_7_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f7NTSOITjLd",
        "outputId": "cc8db821-36cd-472d-9dbe-5fdcdbd5cef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+-----------+-----------+\n",
            "|   ngram|Year|Total_Pages|Total_Books|\n",
            "+--------+----+-----------+-----------+\n",
            "|! $17.95|2002|          5|          5|\n",
            "|! $17.95|2007|          2|          2|\n",
            "|! $17.95|1985|          1|          1|\n",
            "|! $17.95|1990|          1|          1|\n",
            "|! $17.95|1993|          2|          2|\n",
            "|! $17.95|2003|          2|          2|\n",
            "|! $17.95|2000|          9|          9|\n",
            "|! $17.95|2005|         13|         13|\n",
            "|! $17.95|1999|         10|         10|\n",
            "|! $17.95|1992|          5|          5|\n",
            "|! $17.95|1996|          2|          2|\n",
            "|! $17.95|1997|          5|          5|\n",
            "|! $17.95|1995|          1|          1|\n",
            "|! $17.95|1987|          1|          1|\n",
            "|! $17.95|2004|         14|         14|\n",
            "|! $17.95|2006|          5|          5|\n",
            "|! $17.95|1998|          3|          3|\n",
            "|! $17.95|1991|          1|          1|\n",
            "|! $17.95|2008|          2|          2|\n",
            "|! $17.95|2001|          4|          4|\n",
            "+--------+----+-----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+--------+----+----------+----------+\n",
            "|   ngram|Year|sum(Pages)|sum(Books)|\n",
            "+--------+----+----------+----------+\n",
            "|! $17.95|2002|         5|         5|\n",
            "|! $17.95|2007|         2|         2|\n",
            "|! $17.95|1985|         1|         1|\n",
            "|! $17.95|1990|         1|         1|\n",
            "|! $17.95|1993|         2|         2|\n",
            "|! $17.95|2003|         2|         2|\n",
            "|! $17.95|2000|         9|         9|\n",
            "|! $17.95|2005|        13|        13|\n",
            "|! $17.95|1999|        10|        10|\n",
            "|! $17.95|1992|         5|         5|\n",
            "|! $17.95|1996|         2|         2|\n",
            "|! $17.95|1997|         5|         5|\n",
            "|! $17.95|1995|         1|         1|\n",
            "|! $17.95|1987|         1|         1|\n",
            "|! $17.95|2004|        14|        14|\n",
            "|! $17.95|2006|         5|         5|\n",
            "|! $17.95|1998|         3|         3|\n",
            "|! $17.95|1991|         1|         1|\n",
            "|! $17.95|2008|         2|         2|\n",
            "|! $17.95|2001|         4|         4|\n",
            "+--------+----+----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_3_8_sql = spark.sql(\"SELECT Year, COUNT(DISTINCT ngram) as num_distinct_ngrams FROM ngrams GROUP BY Year ORDER BY Year DESC\")\n",
        "result_3_8_sql.show()\n",
        "from pyspark.sql.functions import countDistinct\n",
        "\n",
        "result_3_8_df = df.groupBy(\"Year\").agg(countDistinct(\"ngram\").alias(\"num_distinct_ngrams\")).orderBy(\"Year\", ascending=False)\n",
        "result_3_8_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69qp10WgT7bl",
        "outputId": "ad3f723c-2075-4da1-d6b0-ef4e0a3bfaef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------------+\n",
            "|Year|num_distinct_ngrams|\n",
            "+----+-------------------+\n",
            "|2008|                  2|\n",
            "|2007|                  2|\n",
            "|2006|                  2|\n",
            "|2005|                  2|\n",
            "|2004|                  2|\n",
            "|2003|                  2|\n",
            "|2002|                  2|\n",
            "|2001|                  2|\n",
            "|2000|                  2|\n",
            "|1999|                  2|\n",
            "|1998|                  2|\n",
            "|1997|                  2|\n",
            "|1996|                  2|\n",
            "|1995|                  2|\n",
            "|1993|                  2|\n",
            "|1992|                  2|\n",
            "|1991|                  2|\n",
            "|1990|                  2|\n",
            "|1987|                  2|\n",
            "|1985|                  2|\n",
            "+----+-------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+----+-------------------+\n",
            "|Year|num_distinct_ngrams|\n",
            "+----+-------------------+\n",
            "|2008|                  2|\n",
            "|2007|                  2|\n",
            "|2006|                  2|\n",
            "|2005|                  2|\n",
            "|2004|                  2|\n",
            "|2003|                  2|\n",
            "|2002|                  2|\n",
            "|2001|                  2|\n",
            "|2000|                  2|\n",
            "|1999|                  2|\n",
            "|1998|                  2|\n",
            "|1997|                  2|\n",
            "|1996|                  2|\n",
            "|1995|                  2|\n",
            "|1993|                  2|\n",
            "|1992|                  2|\n",
            "|1991|                  2|\n",
            "|1990|                  2|\n",
            "|1987|                  2|\n",
            "|1985|                  2|\n",
            "+----+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}